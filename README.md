# STaR2025

This repository contains the supplemental material for the anonymous submission:

**STaR: A Self-Triggered Retrieval-Enhanced Framework for Cost-Efficient Generation with LLMs**

## Overview

STaR is a lightweight, plug-and-play framework that enhances large language model (LLM) generation through dynamic, cost-aware retrieval scheduling. It introduces prompt-level mechanisms for information need assessment, query formulation, and structured evidence integration, all without requiring model fine-tuning.

## Current Status

To preserve the anonymity of the review process, core code is currently withheld. Full source code and implementation details will be released in this repository **after the review phase concludes**.

## Repository Structure (planned)

- Experiment scripts and configuration files  
- Dataset setup instructions (for 2WikiMultihopQA, HotpotQA, StrategyQA, IIRC)  
- Reproducibility guidance and environment notes  

## Reproducibility

This repository will support full reproduction of the results reported in the paper, using publicly available quantized LLM models (e.g., LLaMA2-7B/13B, 4-bit). No fine-tuning is required.

## Notice

This repository is shared solely for the purpose of anonymous peer review.
