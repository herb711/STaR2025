# STaR

**Selective Token-aware Retrieval for Dynamic RAG (Retrieval Augmented Generation)**

---

## ğŸ“‘ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…éƒ¨ç½²](#å®‰è£…éƒ¨ç½²)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [è¿è¡ŒæŒ‡å—](#è¿è¡ŒæŒ‡å—)
- [ç»“æœè¯„ä¼°](#ç»“æœè¯„ä¼°)

---

## ğŸ§­ æ¦‚è¿°

STaRï¼ˆSelective Token-aware Retrievalï¼‰æ˜¯ä¸€ä¸ªåŠ¨æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶ï¼Œé€šè¿‡æ™ºèƒ½å†³ç­–æ£€ç´¢æ—¶æœºå’Œå†…å®¹ï¼Œæ˜¾è‘—æå‡å¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡å’Œå‡†ç¡®æ€§ã€‚

### æ ¸å¿ƒç»„ä»¶

- **CIND (Centrality-based Information Needs Detection)ï¼š** åŸºäºä¸­å¿ƒæ€§çš„ä¿¡æ¯éœ€æ±‚æ£€æµ‹ï¼Œé€šè¿‡è¯„ä¼° LLM çš„ä¸ç¡®å®šæ€§ã€token é‡è¦æ€§å’Œè¯­ä¹‰æ„ä¹‰ï¼ŒåŠ¨æ€åˆ¤æ–­æœ€ä½³æ£€ç´¢æ—¶æœº
- **CQG (Centrality-enhanced Query Generation)ï¼š** ä¸­å¿ƒæ€§å¢å¼ºçš„æŸ¥è¯¢ç”Ÿæˆï¼Œç»“åˆä¸­å¿ƒæ€§æƒé‡å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆç²¾å‡†çš„æ£€ç´¢æŸ¥è¯¢

---

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

- **ğŸ¯ åŠ¨æ€æ£€ç´¢ï¼š** æ ¹æ® LLM å®æ—¶ä¿¡æ¯éœ€æ±‚æ™ºèƒ½å†³å®šæ£€ç´¢æ—¶æœºå’Œå†…å®¹
- **âš¡ è½»é‡çº§é›†æˆï¼š** æ— ç¼é›†æˆä»»ä½•åŸºäº Transformer çš„ LLMï¼Œæ— éœ€é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒ
- **ğŸ“ˆ è´¨é‡æå‡ï¼š** ç”Ÿæˆæ›´åŠ ä¿¡æ¯ä¸°å¯Œã€ä¸Šä¸‹æ–‡ç›¸å…³ä¸”è¿è´¯çš„æ–‡æœ¬
- **ğŸ›¡ï¸ å¹»è§‰æ§åˆ¶ï¼š** é€šè¿‡ä¸­å¿ƒæ€§èåˆå’Œä¸€è‡´æ€§æƒ©ç½šæœºåˆ¶ï¼Œæ˜¾è‘—é™ä½å¹»è§‰ç”Ÿæˆ
- **ğŸ”§ é…ç½®çµæ´»ï¼š** æ”¯æŒå¤šç§å‚æ•°è°ƒèŠ‚ï¼Œé€‚åº”ä¸åŒåº”ç”¨åœºæ™¯

---

## ğŸ’» ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿï¼š** Linux / macOS / Windows
- **Pythonï¼š** 3.9+
- **GPUï¼š** æ¨è NVIDIA GPUï¼ˆ8GB+ æ˜¾å­˜ï¼‰
- **å†…å­˜ï¼š** 16GB+ RAM
- **å­˜å‚¨ï¼š** 50GB+ å¯ç”¨ç©ºé—´ï¼ˆç”¨äºæ¨¡å‹å’Œæ•°æ®é›†ï¼‰

---

## ğŸ› ï¸ å®‰è£…éƒ¨ç½²

### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
conda create -n star python=3.9
conda activate star
```

### 2. å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorch
pip install torch==2.1.1

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# ä¸‹è½½è¯­è¨€æ¨¡å‹
python -m spacy download en_core_web_sm
```

### 3. éªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import spacy; print('Spacy: OK')"
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

### æ„å»º Wikipedia ç´¢å¼•

#### 1. ä¸‹è½½ Wikipedia æ•°æ®

```bash
mkdir -p data/dpr
wget -O data/dpr/psgs_w100.tsv.gz https://dl.fbaipublicfiles.com/dpr/wikipedia_split/psgs_w100.tsv.gz
cd data/dpr
gzip -d psgs_w100.tsv.gz
cd ../..
```

#### 2. éƒ¨ç½² Elasticsearch

```bash
cd data
wget -O elasticsearch-7.17.9.tar.gz https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.17.9-linux-x86_64.tar.gz
tar zxvf elasticsearch-7.17.9.tar.gz
rm elasticsearch-7.17.9.tar.gz

# å¯åŠ¨ Elasticsearch
cd elasticsearch-7.17.9
nohup bin/elasticsearch &
cd ../..

# æ„å»ºç´¢å¼•
python prep_elastic.py --data_path data/dpr/psgs_w100.tsv --index_name wiki
```

### ä¸‹è½½è¯„ä¼°æ•°æ®é›†

#### 2WikiMultihopQA
```bash
# æ‰‹åŠ¨ä¸‹è½½åè§£å‹åˆ° data/2wikimultihopqa
# ä¸‹è½½åœ°å€ï¼šhttps://www.dropbox.com/s/ms2m13252h6xubs/data_ids_april7.zip
```

#### StrategyQA
```bash
wget -O data/strategyqa_dataset.zip https://storage.googleapis.com/ai2i/strategyqa/data/strategyqa_dataset.zip
mkdir -p data/strategyqa
unzip data/strategyqa_dataset.zip -d data/strategyqa
rm data/strategyqa_dataset.zip
```

#### HotpotQA
```bash
mkdir -p data/hotpotqa
wget -O data/hotpotqa/hotpotqa-dev.json http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_dev_distractor_v1.json
```

#### IIRC
```bash
wget -O data/iirc.tgz https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_train_dev.tgz
tar -xzvf data/iirc.tgz
mv iirc_train_dev/ data/iirc
rm data/iirc.tgz
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### æ ¸å¿ƒå‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `model_name_or_path` | string | - | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ |
| `method` | string | "STaR" | ä½¿ç”¨çš„æ–¹æ³•åç§° |
| `dataset` | string | - | æ•°æ®é›†åç§°ï¼ˆhotpotqa/2wikimultihopqa/strategyqa/iircï¼‰ |
| `data_path` | string | - | æ•°æ®é›†è·¯å¾„ |
| `output_dir` | string | - | ç»“æœè¾“å‡ºç›®å½• |

### ç”Ÿæˆå‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `generate_max_length` | int | 90 | æœ€å¤§ç”Ÿæˆé•¿åº¦ |
| `fewshot` | int | 6 | Few-shot ç¤ºä¾‹æ•°é‡ |
| `sample` | int | 1000 | é‡‡æ ·æ•°é‡ |

### æ£€ç´¢å‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `retriever` | string | "BM25" | æ£€ç´¢å™¨ç±»å‹ |
| `retrieve_topk` | int | 3 | æ£€ç´¢æ–‡æ¡£æ•°é‡ |
| `retrieve_keep_top_k` | int | 25 | ä¿ç•™çš„å€™é€‰æŸ¥è¯¢æ•°é‡ |
| `query_formulation` | string | "real_words" | æŸ¥è¯¢æ„é€ æ–¹å¼ |

### STaR ç‰¹æœ‰å‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `hallucination_threshold` | float | 0.15 | å¹»è§‰æ£€æµ‹é˜ˆå€¼ |
| `halluc_gamma` | float | 0.3 | å¹»è§‰è°ƒæ•´å‚æ•° |
| `centrality_weight` | float | 0.15 | ä¸­å¿ƒæ€§æƒé‡ |
| `consistency_penalty` | float | 5.0 | ä¸€è‡´æ€§æƒ©ç½šç³»æ•° |

### é…ç½®æ–‡ä»¶æ¨¡æ¿

åˆ›å»º `config/your_config.json`ï¼š

```json
{
    "model_name_or_path": "/path/to/your/model",
    "method": "STaR",
    "dataset": "hotpotqa",
    "data_path": "/path/to/data/hotpotqa",
    "fewshot": 6,
    "sample": 1000,
    "shuffle": false,
    "generate_max_length": 90,
    "query_formulation": "real_words",
    "retrieve_keep_top_k": 25,
    "output_dir": "../result/experiment_name",
    "retriever": "BM25",
    "retrieve_topk": 3,
    "hallucination_threshold": 0.15,
    "halluc_gamma": 0.3,
    "centrality_weight": 0.15,
    "consistency_penalty": 5.0,
    "check_real_words": true,
    "use_counter": true
}
```

---

## ğŸš€ è¿è¡ŒæŒ‡å—

### åŸºç¡€è¿è¡Œ

#### 1. è¿›å…¥å·¥ä½œç›®å½•
```bash
cd src
```

#### 2. å•æ¬¡å®éªŒè¿è¡Œ
```bash
python main.py --config ../config/your_config.json
```

#### 3. æ‰¹é‡å®éªŒè¿è¡Œ
```bash
# è¿è¡Œå¤šä¸ªé…ç½®
for config in ../config/*.json; do
    echo "Running experiment with $config"
    python main.py --config "$config"
done
```

### è¿è¡Œç¤ºä¾‹

#### HotpotQA æ•°æ®é›†
```bash
python main.py --config ../config/hotpotqa_llama2_7b.json
```

#### 2WikiMultihopQA æ•°æ®é›†
```bash
python main.py --config ../config/2wikimultihopqa_llama2_7b.json
```

#### è‡ªå®šä¹‰å‚æ•°è¿è¡Œ
```bash
python main.py \
    --model_path "/path/to/model" \
    --dataset "hotpotqa" \
    --data_path "/path/to/data" \
    --output_dir "../result/custom_experiment" \
    --hallucination_threshold 0.2 \
    --centrality_weight 0.1
```

### ç›‘æ§è¿è¡ŒçŠ¶æ€

#### æŸ¥çœ‹å®æ—¶æ—¥å¿—
```bash
tail -f ../result/experiment_name/*/output.log
```

#### æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µ
```bash
nvidia-smi
watch -n 1 nvidia-smi
```

#### æ£€æŸ¥ Elasticsearch çŠ¶æ€
```bash
curl -X GET "localhost:9200/_cluster/health?pretty"
```

### å¸¸è§é—®é¢˜è§£å†³

#### 1. å†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹å¤„ç†å¤§å°æˆ–æ ·æœ¬æ•°é‡
# åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´ï¼š
{
    "sample": 500,  // å‡å°‘æ ·æœ¬æ•°é‡
    "generate_max_length": 50  // å‡å°‘ç”Ÿæˆé•¿åº¦
}
```

#### 2. Elasticsearch è¿æ¥å¤±è´¥
```bash
# é‡å¯ Elasticsearch
cd data/elasticsearch-7.17.9
bin/elasticsearch-service.sh restart
```

#### 3. æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œæƒé™
ls -la /path/to/model
# ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
df -h
```

---

## ğŸ“ˆ ç»“æœè¯„ä¼°

### è‡ªåŠ¨è¯„ä¼°

è¿è¡Œå®Œæˆåï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨è¾“å‡ºç›®å½•ç”Ÿæˆç»“æœæ–‡ä»¶ï¼š

```bash
# è¿è¡Œè¯„ä¼°è„šæœ¬
cd src
python evaluate.py --dir ../result/experiment_name/run_id
```

### ç»“æœæ–‡ä»¶ç»“æ„

```
result/
â””â”€â”€ experiment_name/
    â””â”€â”€ run_id/
        â”œâ”€â”€ config.json         # å®éªŒé…ç½®
        â”œâ”€â”€ output.txt         # åŸå§‹è¾“å‡ºç»“æœ
        â”œâ”€â”€ details.txt        # è¯„ä¼°è¯¦æƒ…
        â”œâ”€â”€ result.tsv         # è¯„ä¼°æŒ‡æ ‡
        â””â”€â”€ logs/              # è¿è¡Œæ—¥å¿—
```

### è¾“å‡ºæ–‡ä»¶è¯´æ˜

#### config.json
ä¿å­˜å®Œæ•´çš„å®éªŒé…ç½®ï¼Œä¾¿äºå¤ç°å®éªŒã€‚

#### output.txt
åŒ…å«æ¯ä¸ªé—®é¢˜çš„è¯¦ç»†è¾“å‡ºï¼š
```json
{
    "qid": "é—®é¢˜ID",
    "prediction": "æ¨¡å‹é¢„æµ‹ç»“æœ",
    "retrieve_count": 2,        // æ£€ç´¢æ¬¡æ•°
    "generate_count": 3,        // ç”Ÿæˆè½®æ•°
    "hallucinated_count": 0,    // å¹»è§‰æ£€æµ‹æ¬¡æ•°
    "token_count": 64,          // ç”Ÿæˆtokenæ•°
    "sentence_count": 5         // ç”Ÿæˆå¥å­æ•°
}
```

#### details.txt
åŒ…å«è¯„ä¼°è¯¦æƒ…ï¼š
```json
{
    "qid": "é—®é¢˜ID",
    "final_pred": "æœ€ç»ˆæå–çš„ç­”æ¡ˆ",
    "EM": 1.0,                  // ç²¾ç¡®åŒ¹é…åˆ†æ•°
    "F1": 0.95                  // F1åˆ†æ•°
}
```

#### result.tsv
æ±‡æ€»è¯„ä¼°æŒ‡æ ‡ï¼š
```
Metric    Score
EM        0.6234
F1        0.7456
```

### æ€§èƒ½åˆ†æ

#### æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
```bash
# æŸ¥çœ‹æ£€ç´¢ç»Ÿè®¡
grep "retrieve_count" result/*/output.txt | python -c "
import sys, json
counts = [json.loads(line.split(':', 1)[1])['retrieve_count'] for line in sys.stdin]
print(f'å¹³å‡æ£€ç´¢æ¬¡æ•°: {sum(counts)/len(counts):.2f}')
print(f'æœ€å¤§æ£€ç´¢æ¬¡æ•°: {max(counts)}')
"
```

#### ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
```bash
python scripts/generate_report.py --result_dir ../result/experiment_name
```

### å¯¹æ¯”å®éªŒ

#### æ‰¹é‡è¯„ä¼°å¤šä¸ªå®éªŒ
```bash
python scripts/batch_evaluate.py --result_dirs ../result/exp1 ../result/exp2 ../result/exp3
```

#### ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
```bash
python scripts/plot_comparison.py --experiments exp1,exp2,exp3 --metrics EM,F1
```

---

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›é¡¹ç›®ï¼

---

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤ GitHub Issue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

---

## ğŸ”— ç›¸å…³é“¾æ¥

- [è®ºæ–‡åœ°å€](#)
- [æ•°æ®é›†ä¸‹è½½](#)
- [æ¨¡å‹ä¸‹è½½](#)
